{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared Analysis Functions for Reflex MUC 2023\n",
    "\n",
    "## Notebook Summary\n",
    "- Provides reusable helper functions for cleaning, transforming, and exporting study data.\n",
    "- Centralizes shared statistics logic (confidence intervals, whiskers, and descriptive summaries).\n",
    "- Contains reusable plotting routines for condition-level and block-level comparisons.\n",
    "- Includes utility functions for peak processing and derived metrics used across analysis notebooks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Global Configuration\n",
    "This cell imports analysis libraries and defines shared constants such as paths, condition order, and percentiles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared imports for data wrangling, statistics, and plotting.\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import seaborn as sns\n",
    "from scipy.signal import find_peaks, find_peaks_cwt, savgol_filter\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Timestamp format used in result files.\n",
    "timeFormat = \"%Y-%m-%dT%H:%M:%S.%fZ\"\n",
    "\n",
    "# Central output and input directories reused by multiple notebooks.\n",
    "export_data = \"../export/data/\"\n",
    "export_img = \"../export/img/complete/\"\n",
    "export_img_single = \"../export/img/single/\"\n",
    "export_img_questionnaire = \"../export/img/questionnaire/\"\n",
    "\n",
    "export_data_spss = \"../export/spss/\"\n",
    "\n",
    "path = \"../data/\"\n",
    "\n",
    "path_questionnaires = \"../questionnaires/\"\n",
    "\n",
    "# Canonical condition order for grouped analyses and plots.\n",
    "condition_names = ['No Feedback', 'Tactile Feedback', 'Visual Feedback', 'Combined Feedback']\n",
    "\n",
    "# Extra quantiles included in descriptive statistics exports.\n",
    "percentiles = [0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99]\n",
    "\n",
    "sns.set_theme()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Helpers for Data and Results\n",
    "This cell defines functions that persist complete and experiment-only datasets, including validity-filtered result exports.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveData(data_complete):\n",
    "    # Export the full merged tracking dataset.\n",
    "    data_complete.to_csv(rf'../export/data/data_all.csv', sep=\";\", index=False)\n",
    "\n",
    "    # Keep only experiment blocks (training blocks have negative block ids).\n",
    "    data_experiment_only = data_complete[data_complete['Block'] >= 0]\n",
    "\n",
    "    data_experiment_only.to_csv(rf'../export/data/data_experiment.csv', sep=\";\", index=False)\n",
    "\n",
    "def saveResults(results_complete):\n",
    "    # Export all task result rows.\n",
    "    results_complete.to_csv(rf'../export/data/results_all.csv', sep=\";\", index=False)\n",
    "\n",
    "    # Exclude participant 3 from validity-filtered exports.\n",
    "    results_valid = results_complete[results_complete['ProbandId'] != 3]\n",
    "    \n",
    "    results_valid.to_csv(rf'../export/data/results_valid_all.csv', sep=\";\", index=False)\n",
    "\n",
    "    # Keep only experiment blocks for both complete and validity-filtered datasets.\n",
    "    results_experiment_only = results_complete[results_complete['BlockId'] >= 0]\n",
    "    results_valid_experiment_only = results_valid[results_valid['BlockId'] >= 0]\n",
    "\n",
    "    results_experiment_only.to_csv(rf'../export/data/results_experiment.csv', sep=\";\", index=False)\n",
    "    results_valid_experiment_only.to_csv(rf'../export/data/results_experiment_valid.csv', sep=\";\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak Data Load and Save Utilities\n",
    "This cell provides helper functions to deserialize and serialize array-like peak columns when reading from or writing to CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPeaks(recoverArrayColumns = []):\n",
    "    result = pd.read_csv(rf'{export_data}all_peaks.csv', sep= \";\")\n",
    "\n",
    "    # Convert serialized list strings back into numpy arrays after CSV import.\n",
    "    for col in recoverArrayColumns:\n",
    "        result[col] = result[col].apply(lambda item: np.fromstring(item.replace('[','').replace(']',''), dtype=float, sep=\"|\"))\n",
    "   \n",
    "    return result\n",
    "\n",
    "def savePeaks(result_all, writeArrayColumns = []):\n",
    "    # Serialize numpy arrays with a custom separator so they survive CSV export/import.\n",
    "    for col in writeArrayColumns:\n",
    "        result_all[col] = result_all[col].apply(lambda item: np.array2string(item, separator=\"|\"))\n",
    "    \n",
    "    result_all.to_csv(rf'{export_data}all_peaks.csv', sep= \";\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last Layer-Change Lookup\n",
    "This cell adds a helper that finds the most recent non-zero layer-change event before a given row index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLastLayerChange(index):\n",
    "    # Find the latest non-zero layer change before the current row index.\n",
    "    data = data_complete[(data_complete['LayerChange'] != 0) & (data_complete.index < index)].tail(1)\n",
    "\n",
    "    date = data['Date'].values[0]\n",
    "    idx = data.index.values[0]\n",
    "    \n",
    "    return (date, idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Margin Helper\n",
    "This cell defines a plotting utility that expands axis limits by a configurable relative margin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_margin(ax,x=0.05,y=0.05):\n",
    "    # Expand axis limits by a relative margin to avoid clipped data and labels.\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "\n",
    "    xmargin = (xlim[1]-xlim[0])*x\n",
    "    ymargin = (ylim[1]-ylim[0])*y\n",
    "\n",
    "    ax.set_xlim(xlim[0]-xmargin,xlim[1]+xmargin)\n",
    "    ax.set_ylim(ylim[0]-ymargin,ylim[1]+ymargin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Utility Functions\n",
    "This cell provides reusable helpers to compute 95% confidence intervals and Tukey-style whiskers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCI(df, m= 'mean', c='count', s='std'):\n",
    "    # Add 95% confidence interval bounds using a normal approximation.\n",
    "    df['ci95_hi'] = df[m] + 1.96*df[s]/(df[c].apply(np.sqrt))\n",
    "    df['ci95_lo'] = df[m] - 1.96*df[s]/(df[c].apply(np.sqrt))\n",
    "\n",
    "def computeWhiskers(df, desc, col_names, q1='25%', q3='75%'):\n",
    "    desc['iqr'] = desc[q3] - desc[q1]\n",
    "\n",
    "    # Compute Tukey inner-fence bounds (1.5 * IQR).\n",
    "    desc['lower_bound'] = desc[q1] - 1.5 * desc['iqr']\n",
    "    desc['upper_bound'] = desc[q3] + 1.5 * desc['iqr']    \n",
    "\n",
    "    lower_whiskers = []\n",
    "    upper_whiskers = []\n",
    "\n",
    "    for col_name in col_names:\n",
    "        lower_bound = desc['lower_bound'].T[col_name]\n",
    "        upper_bound = desc['upper_bound'].T[col_name]\n",
    "\n",
    "        # Whiskers are the furthest observed values within the inner fences.\n",
    "        l = df[df[col_name] >= lower_bound][col_name].min()\n",
    "        u = df[df[col_name] <= upper_bound][col_name].max()\n",
    "\n",
    "        lower_whiskers.append(l)\n",
    "        upper_whiskers.append(u)\n",
    "\n",
    "    desc['lower_whisker'] = lower_whiskers\n",
    "    desc['upper_whisker'] = upper_whiskers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condition-Based Statistics and Plot Generation\n",
    "This cell computes descriptive statistics and exports summary tables and plots across conditions, blocks, and trial progression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeStatistics(data_complete, columnName = 'DurationMS', filePrefix='duration', title='Duration', label_y='Time (s)'):\n",
    "    conditions = data_complete.groupby(['Condition'])\n",
    "\n",
    "    # Pivot to one column per condition, aligned by within-condition trial counter.\n",
    "    # Reindex keeps the predefined condition order across exports and plots.\n",
    "    condition_duration = data_complete.pivot_table(columns=['Condition'], values=[columnName], index=['countCondition'])[columnName].reindex(columns=condition_names)\n",
    "\n",
    "    display(condition_duration)\n",
    "\n",
    "    # Export condition-level trial values.\n",
    "    condition_duration.to_csv(rf'{export_data}{filePrefix}_allTrials.csv', sep=\";\", index=False)\n",
    "\n",
    "    # Average metric per block and condition for block-wise comparison.\n",
    "    condition_duration_block = data_complete.groupby(['Condition', 'BlockId'])[columnName].mean().unstack(level=0).reindex(columns=condition_names)\n",
    "\n",
    "    # Rearrange the same table so conditions become rows and blocks columns.\n",
    "    condition_block_duration = condition_duration_block.stack().unstack(level = 0)\n",
    "\n",
    "    display(condition_block_duration)\n",
    "\n",
    "    condition_block_duration.to_csv(rf'{export_data}{filePrefix}_trialsBlockCondition.csv', sep=\";\", index=False)\n",
    "\n",
    "    # Compute descriptive statistics and confidence intervals per condition and overall.\n",
    "    durations_desc = condition_duration.describe(percentiles=percentiles)\n",
    "\n",
    "    stats = pd.DataFrame(durations_desc).T\n",
    "    stats_total = pd.DataFrame(data_complete[columnName].describe()).T\n",
    "\n",
    "    computeCI(stats)\n",
    "    computeCI(stats_total)\n",
    "\n",
    "    computeWhiskers(condition_duration, stats, condition_names)\n",
    "    # computeWhiskers(condition_duration, stats_total, [])\n",
    "\n",
    "    display(durations_desc)\n",
    "\n",
    "    stats_complete = pd.concat([stats, stats_total], ignore_index=False)\n",
    "\n",
    "    display(stats_complete.T)\n",
    "\n",
    "    stats_complete.to_csv(rf'{export_data}{filePrefix}_stats.csv', sep=\";\", index=True)\n",
    "\n",
    "    # Pivot by trial id to inspect learning effects over the block sequence.\n",
    "    durations = data_complete.pivot_table(index='TrialId', columns=['Condition'], values=columnName).reindex(columns=condition_names)\n",
    "\n",
    "    display(durations)\n",
    "\n",
    "    durations.to_csv(rf'{export_data}{filePrefix}_trialsBlock.csv', sep=\";\", index=False)\n",
    "\n",
    "    # Line plot: metric per trial split by condition.\n",
    "    fig0, ax0 = plt.subplots(figsize=(25,8))\n",
    "\n",
    "    condition_duration.plot(ax = ax0)\n",
    "\n",
    "    ax0.set_xlabel('Trial')\n",
    "    ax0.set_ylabel(label_y)\n",
    "\n",
    "    plt.title(f'{title} of each trial by Condition')\n",
    "    \n",
    "\n",
    "    fig0.savefig(rf'{export_img}{filePrefix}_allTrials.png')\n",
    "    fig0.savefig(rf'{export_img}{filePrefix}_allTrials.svg')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    # Line plot over trial number (block progression).\n",
    "    fig1, ax1 = plt.subplots(figsize=(25,8))\n",
    "\n",
    "    durations.plot(ax = ax1)\n",
    "\n",
    "    ax1.set_xlabel('Trial Number')\n",
    "    ax1.set_ylabel(label_y)\n",
    "    ax1.set_xticks(np.arange(0, 21, step=1))\n",
    "\n",
    "    plt.title(f'{title} over the Block')\n",
    "\n",
    "    fig1.savefig(rf'{export_img}{filePrefix}_trialsBlock-plot.png')\n",
    "    fig1.savefig(rf'{export_img}{filePrefix}_trialsBlock-plot.svg')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Regression-style trend plot with jittered observations and mean estimator.\n",
    "    sns.set_theme(font_scale = 1.5, palette=['#ea5b0c', '#1d71b8', '#3aaa35', '#e7267a'])\n",
    "    sns.set_style(\"white\")\n",
    "    g = sns.lmplot(x='TrialId', y=columnName, hue='Condition', hue_order=condition_names, data = data_complete, height=8, aspect=2, x_estimator=np.mean, scatter=True, x_jitter=0.5, y_jitter=0.5)\n",
    "    g.set(title=f'{title} over the Block')    \n",
    "    g.set(xlabel='Trial Number')\n",
    "    g.set(ylabel=label_y)\n",
    "    g.set(xticks=np.arange(0, 21, step=1))\n",
    "\n",
    "    for ax in plt.gcf().axes:\n",
    "        add_margin(ax,x=0.05,y=0.01)\n",
    "\n",
    "    g.savefig(rf'{export_img}{filePrefix}_trialsBlock-reg.png')\n",
    "    g.savefig(rf'{export_img}{filePrefix}_trialsBlock-reg.svg')\n",
    "\n",
    "    # for ax in plt.gcf().axes:\n",
    "    #     l = ax.get_xlabel()\n",
    "    #     ax.set_xlabel(l, fontsize=15)\n",
    "    #     l = ax.get_ylabel()\n",
    "    #     ax.set_ylabel(l, fontsize=15)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Box plot: per-condition distribution summary.\n",
    "    fig2, ax2 = plt.subplots(figsize=(9,9))\n",
    "\n",
    "    condition_duration.boxplot(ax = ax2) \n",
    "\n",
    "    ax2.set_xlabel('Condition')\n",
    "    ax2.set_ylabel(label_y)\n",
    "    ax2.yaxis.grid(False)\n",
    "    ax2.xaxis.grid(False)\n",
    "\n",
    "    plt.title(f'Median {title} per Condition')\n",
    "\n",
    "    fig2.savefig(rf'{export_img}{filePrefix}_trialsCondition-box.png')\n",
    "    fig2.savefig(rf'{export_img}{filePrefix}_trialsCondition-box.svg')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Bar plot: mean per block and condition.\n",
    "    fig3, ax3 = plt.subplots(figsize=(25,8))\n",
    "\n",
    "    condition_duration_block.plot(ax = ax3, kind=\"bar\")\n",
    "\n",
    "    ax3.set_xlabel('Block')\n",
    "    ax3.set_ylabel(label_y)\n",
    "\n",
    "    plt.title(f'Median Trial {title} per Block and Condition')\n",
    "\n",
    "    fig3.savefig(rf'{export_img}{filePrefix}_trialsBlockCondition-bar.png')\n",
    "    fig3.savefig(rf'{export_img}{filePrefix}_trialsBlockCondition-bar.svg')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Bar plot: same data, transposed orientation (condition x block).\n",
    "    fig4, ax4 = plt.subplots(figsize=(25,8))\n",
    "\n",
    "    condition_block_duration.plot(ax = ax4, kind=\"bar\")\n",
    "\n",
    "    ax4.set_xlabel('Condition')\n",
    "    ax4.set_ylabel(label_y)\n",
    "\n",
    "    plt.title(f'Median Trial {title} per Condition and Block')\n",
    "\n",
    "    fig4.savefig(rf'{export_img}{filePrefix}_trialsConditionBlock-bar.png')\n",
    "    fig4.savefig(rf'{export_img}{filePrefix}_trialsConditionBlock-bar.svg')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Boxplot Statistics Routine\n",
    "This cell defines a reusable grouped-statistics and boxplot function with optional export and extended metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateBoxPlotStats(data, groupCol, indexColumns, statsColumn, xLabel, yLabel, title, filename, save= False, show = False, reindexColumns = False, outliers = False, ylim = [], extendedStats = True):\n",
    "    # Build grouped descriptive statistics for the selected metric.\n",
    "    grouped = data.groupby(groupCol)\n",
    "\n",
    "    desc = grouped[statsColumn].describe().transpose()\n",
    "\n",
    "    if reindexColumns:\n",
    "        desc = desc.reindex(columns=condition_names)   \n",
    "\n",
    "    display(desc)\n",
    "\n",
    "    # Pivot raw values into one column per group for boxplot rendering.\n",
    "    desc_pivot = data.pivot_table(columns=groupCol, index=indexColumns, values=statsColumn)\n",
    "\n",
    "    if reindexColumns:\n",
    "        desc_pivot = desc_pivot.reindex(columns=condition_names)    \n",
    "\n",
    "    # Optionally compute extended summary stats and export them.\n",
    "    if extendedStats == True:\n",
    "        desc2 = desc_pivot.describe(percentiles=percentiles)\n",
    "        stats = pd.DataFrame(desc2).T\n",
    "        stats_total = pd.DataFrame(data[statsColumn].describe()).T\n",
    "\n",
    "        computeCI(stats)\n",
    "        computeCI(stats_total)\n",
    "\n",
    "        computeWhiskers(desc_pivot, stats, condition_names)\n",
    "\n",
    "        stats_complete = pd.concat([stats, stats_total], ignore_index=True)\n",
    "\n",
    "        display(stats_complete.T)\n",
    "\n",
    "        stats_complete.to_csv(rf'{export_data}{filename}_stats.csv', sep=\";\", index=True)\n",
    "\n",
    "    # Draw the distribution chart with optional outliers and y-limits.\n",
    "    fig1, ax1 = plt.subplots(figsize=(8,8))\n",
    "\n",
    "    sns.boxplot(data = desc_pivot, ax = ax1, showfliers=outliers)\n",
    "\n",
    "    ax1.set_xlabel(xLabel)\n",
    "    ax1.set_ylabel(yLabel)\n",
    "    ax1.yaxis.grid(False)\n",
    "    ax1.xaxis.grid(False)\n",
    "    if len(ylim) == 2:\n",
    "        ax1.set_ylim(ylim[0], ylim[1])\n",
    "\n",
    "    plt.title(title)\n",
    "\n",
    "    if save:  \n",
    "        fig1.savefig(rf'{export_img}{filename}-box.png')\n",
    "        fig1.savefig(rf'{export_img}{filename}-box.svg')\n",
    "    \n",
    "    if show: \n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak Z-Difference Computation\n",
    "This cell computes within-trial z-differences for ordered peaks while resetting differences at trial boundaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeDifferenceZ(peaks):\n",
    "    # Ensure temporal order before computing sequential differences.\n",
    "    peaks = peaks.sort_values(['Date']).reset_index()\n",
    "    peaks['Diff_Z'] = peaks['Peak_Z'].diff()\n",
    "    peaks['Diff_Trial'] = peaks['Trial'].diff()\n",
    "\n",
    "    # Mark the first row as a trial boundary.\n",
    "    peaks.loc[0, 'Diff_Trial'] = 1\n",
    "\n",
    "    # Reset z-difference at trial boundaries to avoid cross-trial subtraction.\n",
    "    peaks.loc[peaks['Diff_Trial'] != 0, 'Diff_Z'] = 0\n",
    "\n",
    "    return peaks\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
